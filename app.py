import streamlit as st
import google.generativeai as genai
from PIL import Image
from gtts import gTTS
import io

# --- 1. C·∫•u h√¨nh trang (Layout Wide ƒë·ªÉ chia 2 c·ªôt) ---
st.set_page_config(page_title="VisionVoice", page_icon="‚ú®", layout="wide")

# --- 2. C·∫•u h√¨nh API Key ---
try:
    if "GOOGLE_API_KEY" in st.secrets:
        genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
    else:
        st.error("‚ö†Ô∏è Ch∆∞a t√¨m th·∫•y API Key trong Secrets.")
        st.stop()
except Exception as e:
    st.error(f"L·ªói c·∫•u h√¨nh: {e}")

# --- 3. CSS T√πy ch·ªânh ƒë·ªÉ gi·ªëng giao di·ªán Card (T√πy ch·ªçn) ---
st.markdown("""
<style>
    .stTextArea textarea {
        background-color: #f0f2f6;
        border-radius: 10px;
    }
</style>
""", unsafe_allow_html=True)

# --- 4. Kh·ªüi t·∫°o Session State (ƒê·ªÉ l∆∞u vƒÉn b·∫£n sau khi AI qu√©t xong) ---
if 'extracted_text' not in st.session_state:
    st.session_state['extracted_text'] = ""

# --- 5. Header ---
st.markdown("<h1 style='text-align: center;'>‚ú® VisionVoice</h1>", unsafe_allow_html=True)
st.markdown("<p style='text-align: center;'>Upload an image to extract text and listen with AI speech.</p>", unsafe_allow_html=True)
st.write("") # Kho·∫£ng tr·∫Øng

# --- 6. Giao di·ªán ch√≠nh (Chia 2 c·ªôt) ---
col1, col2 = st.columns(2, gap="large")

# === C·ªòT TR√ÅI: INPUT (SOURCE) ===
with col1:
    st.subheader("üñºÔ∏è Source")
    
    # Tab ch·ªçn File ho·∫∑c Text (Gi·∫£ l·∫≠p b·∫±ng Radio)
    source_type = st.radio("Ch·ªçn ngu·ªìn:", ["File Upload", "Nh·∫≠p tay"], horizontal=True, label_visibility="collapsed")
    
    if source_type == "File Upload":
        # Khung upload ·∫£nh
        uploaded_file = st.file_uploader("Choose an image...", type=["jpg", "jpeg", "png"])
        
        if uploaded_file:
            # Hi·ªÉn th·ªã ·∫£nh
            image = Image.open(uploaded_file)
            st.image(image, caption="·∫¢nh g·ªëc", use_column_width=True)
            
            # N√∫t Qu√©t ch·ªØ (OCR)
            if st.button("üîç Tr√≠ch xu·∫•t vƒÉn b·∫£n (OCR)", type="primary", use_container_width=True):
                with st.spinner("Gemini ƒëang ƒë·ªçc ·∫£nh..."):
                    try:
                        model = genai.GenerativeModel('gemini-1.5-flash')
                        # Prompt y√™u c·∫ßu ch·ªâ tr√≠ch xu·∫•t ch·ªØ
                        response = model.generate_content(["H√£y tr√≠ch xu·∫•t to√†n b·ªô vƒÉn b·∫£n c√≥ trong b·ª©c ·∫£nh n√†y. Ch·ªâ tr·∫£ v·ªÅ n·ªôi dung vƒÉn b·∫£n, kh√¥ng th√™m l·ªùi b√¨nh lu·∫≠n.", image])
                        st.session_state['extracted_text'] = response.text
                        st.rerun() # T·∫£i l·∫°i trang ƒë·ªÉ c·∫≠p nh·∫≠t c·ªôt b√™n ph·∫£i
                    except Exception as e:
                        st.error(f"L·ªói: {e}")
    else:
        st.info("Chuy·ªÉn sang ch·∫ø ƒë·ªô nh·∫≠p tay b√™n c·ªôt ph·∫£i ->")

# === C·ªòT PH·∫¢I: OUTPUT (CONTENT & TTS) ===
with col2:
    st.subheader("üìù Content")
    
    # √î hi·ªÉn th·ªã vƒÉn b·∫£n (Cho ph√©p s·ª≠a)
    text_content = st.text_area(
        "N·ªôi dung vƒÉn b·∫£n:",
        value=st.session_state['extracted_text'],
        height=300,
        placeholder="VƒÉn b·∫£n ƒë∆∞·ª£c tr√≠ch xu·∫•t s·∫Ω hi·ªán ·ªü ƒë√¢y...",
        label_visibility="collapsed"
    )
    
    # C·∫≠p nh·∫≠t l·∫°i session state n·∫øu ng∆∞·ªùi d√πng s·ª≠a b·∫±ng tay
    if text_content != st.session_state['extracted_text']:
         st.session_state['extracted_text'] = text_content

    st.divider()
    
    # Khu v·ª±c ƒëi·ªÅu khi·ªÉn gi·ªçng n√≥i
    c1, c2 = st.columns([1, 2])
    with c1:
        # Ch·ªçn ng√¥n ng·ªØ ƒë·ªçc
        lang_option = st.selectbox("Gi·ªçng ƒë·ªçc", ["Ti·∫øng Vi·ªát (vi)", "English (en)", "Korean (ko)", "Japanese (ja)"])
        lang_code = lang_option.split("(")[1].replace(")", "") # L·∫•y m√£ 'vi', 'en'...
    
    with c2:
        st.write("") # CƒÉn ch·ªânh l·ªÅ
        st.write("") 
        if st.button("üîä Read Aloud (ƒê·ªçc ngay)", use_container_width=True):
            if text_content.strip():
                try:
                    # S·ª≠ d·ª•ng gTTS ƒë·ªÉ t·∫°o file √¢m thanh
                    tts = gTTS(text=text_content, lang=lang_code)
                    
                    # L∆∞u v√†o b·ªô nh·ªõ ƒë·ªám thay v√¨ l∆∞u file c·ª©ng
                    sound_file = io.BytesIO()
                    tts.write_to_fp(sound_file)
                    
                    # Ph√°t √¢m thanh
                    st.audio(sound_file, format='audio/mp3')
                except Exception as e:
                    st.error(f"L·ªói t·∫°o gi·ªçng n√≥i: {e}")
            else:
                st.warning("Ch∆∞a c√≥ n·ªôi dung ƒë·ªÉ ƒë·ªçc!")
