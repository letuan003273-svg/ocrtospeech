import streamlit as st
import google.generativeai as genai
from PIL import Image
import edge_tts
import asyncio
import tempfile # Äá»ƒ táº¡o file táº¡m thá»i

# --- 1. Cáº¥u hÃ¬nh trang ---
st.set_page_config(page_title="VisionVoice Pro", page_icon="ğŸ™ï¸", layout="wide")

# --- 2. Cáº¥u hÃ¬nh API Key ---
try:
    if "GOOGLE_API_KEY" in st.secrets:
        genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
    else:
        st.error("âš ï¸ ChÆ°a tÃ¬m tháº¥y API Key.")
        st.stop()
except Exception as e:
    st.error(f"Lá»—i cáº¥u hÃ¬nh: {e}")

# --- 3. HÃ m xá»­ lÃ½ giá»ng Ä‘á»c Edge-TTS (Má»šI) ---
async def text_to_speech_edge(text, voice_name):
    communicate = edge_tts.Communicate(text, voice_name)
    # Táº¡o file táº¡m trong bá»™ nhá»› Ä‘á»ƒ lÆ°u Ã¢m thanh
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as tmp_file:
        await communicate.save(tmp_file.name)
        return tmp_file.name

# --- 4. Session State ---
if 'extracted_text' not in st.session_state:
    st.session_state['extracted_text'] = ""

# --- 5. Giao diá»‡n ---
st.title("ğŸ™ï¸ VisionVoice Pro")
st.caption("Sá»­ dá»¥ng Gemini 1.5 Flash & Giá»ng Ä‘á»c Neural siÃªu thá»±c")

col1, col2 = st.columns(2, gap="large")

# === Cá»˜T TRÃI: INPUT ===
with col1:
    st.subheader("ğŸ–¼ï¸ HÃ¬nh áº£nh")
    uploaded_file = st.file_uploader("Táº£i áº£nh lÃªn", type=["jpg", "png", "jpeg"])
    
    if uploaded_file:
        image = Image.open(uploaded_file)
        st.image(image, caption="áº¢nh gá»‘c", use_column_width=True)
        
        if st.button("ğŸ” QuÃ©t vÄƒn báº£n (OCR)", type="primary", use_container_width=True):
            with st.spinner("Äang Ä‘á»c áº£nh..."):
                try:
                    model = genai.GenerativeModel('gemini-2.5-flash')
                    response = model.generate_content(["TrÃ­ch xuáº¥t nguyÃªn vÄƒn ná»™i dung vÄƒn báº£n trong áº£nh nÃ y.", image])
                    st.session_state['extracted_text'] = response.text
                    st.rerun()
                except Exception as e:
                    st.error(f"Lá»—i: {e}")

# === Cá»˜T PHáº¢I: OUTPUT ===
with col2:
    st.subheader("ğŸ“ VÄƒn báº£n & Giá»ng nÃ³i")
    
    text_content = st.text_area(
        "Ná»™i dung:",
        value=st.session_state['extracted_text'],
        height=300
    )
    
    # Cáº­p nháº­t láº¡i náº¿u sá»­a tay
    if text_content != st.session_state['extracted_text']:
         st.session_state['extracted_text'] = text_content

    st.divider()
    
    # Chá»n giá»ng Ä‘á»c (CÃ¡c giá»ng xá»‹n cá»§a Microsoft)
    voice_options = {
        "Tiáº¿ng Viá»‡t - HoÃ i My (Ná»¯ - Nháº¹ nhÃ ng)": "vi-VN-HoaiMyNeural",
        "Tiáº¿ng Viá»‡t - Nam Minh (Nam - Tráº§m áº¥m)": "vi-VN-NamMinhNeural",
        "Tiáº¿ng Anh - Aria (Ná»¯)": "en-US-AriaNeural",
        "Tiáº¿ng Anh - Christopher (Nam)": "en-US-ChristopherNeural"
    }
    
    selected_voice_label = st.selectbox("Chá»n giá»ng Ä‘á»c:", list(voice_options.keys()))
    selected_voice_code = voice_options[selected_voice_label]

    if st.button("ğŸ”Š Äá»c Ngay (Neural Voice)", use_container_width=True):
        if text_content.strip():
            with st.spinner("Äang táº¡o giá»ng nÃ³i (Máº¥t khoáº£ng 2-3 giÃ¢y)..."):
                try:
                    # Cháº¡y hÃ m báº¥t Ä‘á»“ng bá»™ (async)
                    audio_file_path = asyncio.run(text_to_speech_edge(text_content, selected_voice_code))
                    
                    # PhÃ¡t Ã¢m thanh
                    st.audio(audio_file_path, format='audio/mp3')
                    st.success("ÄÃ£ táº¡o xong!")
                except Exception as e:
                    st.error(f"Lá»—i giá»ng nÃ³i: {e}")
        else:
            st.warning("ChÆ°a cÃ³ ná»™i dung Ä‘á»ƒ Ä‘á»c!")
