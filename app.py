import streamlit as st
import google.generativeai as genai
from PIL import Image
import requests
import io

# --- 1. C·∫•u h√¨nh trang ---
st.set_page_config(page_title="VisionVoice Pro", page_icon="üíé", layout="wide")

# --- 2. GIAO DI·ªÜN C·∫§U H√åNH KEY (SIDEBAR) ---
with st.sidebar:
    st.header("üîë Qu·∫£n l√Ω API Key")
    st.markdown("N·∫øu Key m·∫∑c ƒë·ªãnh h·∫øt h·∫°n, h√£y nh·∫≠p Key m·ªõi v√†o d∆∞·ªõi ƒë√¢y ƒë·ªÉ ti·∫øp t·ª•c d√πng ngay l·∫≠p t·ª©c.")
    
    # Ki·ªÉm tra tr·∫°ng th√°i Key Google
    if "GOOGLE_API_KEY" in st.secrets:
        st.success("‚úÖ Google API Key: ƒê√£ k·∫øt n·ªëi")
        genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
    else:
        st.error("‚ö†Ô∏è Ch∆∞a c√≥ Google API Key trong Secrets")
    
    st.divider()
    
    # --- QU·∫¢N L√ù ELEVENLABS KEY ---
    st.subheader("ElevenLabs Key")
    
    # 1. Ki·ªÉm tra Key trong Secrets
    default_eleven_key = st.secrets.get("ELEVENLABS_API_KEY", None)
    if default_eleven_key:
        st.info(f"Key m·∫∑c ƒë·ªãnh (Secrets): ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢{default_eleven_key[-4:]}")
    else:
        st.warning("Ch∆∞a c√≥ Key m·∫∑c ƒë·ªãnh trong Secrets.")
        
    # 2. √î nh·∫≠p Key d·ª± ph√≤ng (∆Øu ti√™n d√πng c√°i n√†y n·∫øu c√≥ nh·∫≠p)
    custom_eleven_key = st.text_input(
        "Nh·∫≠p Key kh√°c (∆Øu ti√™n):", 
        type="password",
        placeholder="sk_..."
    )
    
    # Logic ch·ªçn Key: N·∫øu c√≥ nh·∫≠p tay th√¨ d√πng nh·∫≠p tay, kh√¥ng th√¨ d√πng m·∫∑c ƒë·ªãnh
    FINAL_ELEVEN_KEY = custom_eleven_key if custom_eleven_key else default_eleven_key

# --- 3. H√†m g·ªçi API ElevenLabs ---
def text_to_speech_elevenlabs(text, voice_id, api_key):
    url = f"https://api.elevenlabs.io/v1/text-to-speech/{voice_id}"
    headers = {
        "Accept": "audio/mpeg",
        "Content-Type": "application/json",
        "xi-api-key": api_key
    }
    data = {
        "text": text,
        "model_id": "eleven_multilingual_v2",
        "voice_settings": {"stability": 0.5, "similarity_boost": 0.75}
    }
    try:
        response = requests.post(url, json=data, headers=headers)
        if response.status_code == 200:
            return response.content
        elif response.status_code == 401:
            st.error("‚ùå L·ªói 401: API Key n√†y kh√¥ng h·ª£p l·ªá ho·∫∑c ƒë√£ h·∫øt h·∫°n.")
            return None
        else:
            st.error(f"L·ªói ElevenLabs ({response.status_code}): {response.text}")
            return None
    except Exception as e:
        st.error(f"L·ªói k·∫øt n·ªëi: {e}")
        return None

# --- 4. Session State ---
if 'extracted_text' not in st.session_state:
    st.session_state['extracted_text'] = ""

# --- 5. Giao di·ªán Ch√≠nh ---
st.title("üíé VisionVoice Pro")
st.caption("H·ªó tr·ª£ thay ƒë·ªïi nhi·ªÅu API Key linh ho·∫°t")

col1, col2 = st.columns(2, gap="large")

# === C·ªòT TR√ÅI: INPUT ===
with col1:
    st.subheader("üñºÔ∏è H√¨nh ·∫£nh")
    uploaded_file = st.file_uploader("T·∫£i ·∫£nh l√™n", type=["jpg", "png", "jpeg"])
    
    if uploaded_file:
        image = Image.open(uploaded_file)
        st.image(image, caption="·∫¢nh g·ªëc", use_column_width=True)
        
        if st.button("üîç Qu√©t vƒÉn b·∫£n (OCR)", type="primary", use_container_width=True):
            with st.spinner("Gemini ƒëang ƒë·ªçc ·∫£nh..."):
                try:
                    model = genai.GenerativeModel('gemini-2.5-flash')
                    response = model.generate_content(["Tr√≠ch xu·∫•t n·ªôi dung vƒÉn b·∫£n.", image])
                    st.session_state['extracted_text'] = response.text
                    st.rerun()
                except Exception as e:
                    st.error(f"L·ªói OCR: {e}")

# === C·ªòT PH·∫¢I: OUTPUT ===
with col2:
    st.subheader("üìù & üîä ElevenLabs")
    
    text_content = st.text_area("N·ªôi dung:", value=st.session_state['extracted_text'], height=250)
    
    if text_content != st.session_state['extracted_text']:
         st.session_state['extracted_text'] = text_content

    st.divider()
    
    voice_options = {
        "Rachel (N·ªØ - Chu·∫©n)": "21m00Tcm4TlvDq8ikWAM",
        "Clyde (Nam - Tr·∫ßm)": "2EiwWnXFnvU5JabPnv8n",
        "Mimi (N·ªØ - Tr·∫ª con)": "ZrHiDhxje0jIeF18mMVI",
        "Fin (Nam - M·∫°nh)": "D38z5RcWu1voky8WS1ja"
    }
    selected_voice_name = st.selectbox("Ch·ªçn gi·ªçng:", list(voice_options.keys()))
    selected_voice_id = voice_options[selected_voice_name]

    if st.button("üîä ƒê·ªçc Ngay", type="secondary", use_container_width=True):
        if not FINAL_ELEVEN_KEY:
            st.error("‚õî Ch∆∞a c√≥ API Key! Vui l√≤ng nh·∫≠p Key v√†o thanh b√™n tr√°i.")
        elif text_content.strip():
            with st.spinner("ElevenLabs ƒëang x·ª≠ l√Ω..."):
                audio_bytes = text_to_speech_elevenlabs(text_content, selected_voice_id, FINAL_ELEVEN_KEY)
                if audio_bytes:
                    st.audio(audio_bytes, format="audio/mp3")
                    st.success("Xong!")
        else:
            st.warning("Ch∆∞a c√≥ n·ªôi dung!")
